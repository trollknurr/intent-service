{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./c_train.csv')\n",
    "test_df = pd.read_csv('./c_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    device=\"mps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = train_df['intent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748547ccc2d14f19a0cb89df7dcd6eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_label = []\n",
    "for ix, row in tqdm(test_df.iterrows()):\n",
    "    p = classifier(row['query'], candidate_labels)\n",
    "    label = p['labels'][np.argmax(p['scores'])]\n",
    "    predicted_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6081\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  abbreviation       0.60      0.96      0.74        26\n",
      "      aircraft       0.35      0.75      0.48         8\n",
      "       airfare       0.24      0.87      0.37        61\n",
      "       airline       0.42      0.53      0.47        30\n",
      "       airport       0.36      0.77      0.49        13\n",
      "      capacity       1.00      0.62      0.76        21\n",
      "      cheapest       0.00      0.00      0.00         0\n",
      "          city       0.00      0.00      0.00         5\n",
      "      day_name       0.00      0.00      0.00         2\n",
      "      distance       0.20      0.90      0.32        10\n",
      "        flight       0.95      0.61      0.74       627\n",
      "     flight_no       0.00      0.00      0.00         9\n",
      "   flight_time       0.00      0.00      0.00         1\n",
      "   ground_fare       0.00      0.00      0.00         7\n",
      "ground_service       1.00      0.31      0.47        36\n",
      "          meal       0.75      0.50      0.60         6\n",
      "      quantity       0.00      0.00      0.00         3\n",
      "   restriction       0.00      0.00      0.00         0\n",
      "\n",
      "      accuracy                           0.61       865\n",
      "     macro avg       0.33      0.38      0.30       865\n",
      "  weighted avg       0.82      0.61      0.66       865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonysh/Projects/mY/Ultimate ML Engineer Challenge 2025/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/tonysh/Projects/mY/Ultimate ML Engineer Challenge 2025/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/tonysh/Projects/mY/Ultimate ML Engineer Challenge 2025/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/tonysh/Projects/mY/Ultimate ML Engineer Challenge 2025/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/tonysh/Projects/mY/Ultimate ML Engineer Challenge 2025/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/tonysh/Projects/mY/Ultimate ML Engineer Challenge 2025/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print metrics\n",
    "test_accuracy = accuracy_score(test_df['intent'], predicted_label)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_df['intent'], predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: performance are quite poor\n",
    "Plus:\n",
    "* No dataset and training needed\n",
    "* If find appropriate model, can be multi-lingual\n",
    "\n",
    "Minus:\n",
    "* Slow and poor perfomancs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
